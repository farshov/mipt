select() and  pselect()  allow  a  program  to  monitor  multiple  file descriptors,  waiting  until one or more of the file descriptors become "ready" for some class of I/O operation (e.g., input possible).  A file descriptor  is  considered  ready if it is possible to perform a corresponding I/O operation (e.g., read(2) without  blocking,  or  a  sufficiently small write(2)).

The  operation of select() and pselect() is identical, other than these three differences:

       (i)    select() uses a timeout that is a struct timeval  (with  seconds and  microseconds), while pselect() uses a struct timespec (with seconds and nanoseconds).

       (ii)   select() may update the timeout argument to  indicate  how  much time was left.  pselect() does not change this argument.

       (iii)  select()  has  no  sigmask  argument,  and  behaves as pselect() called with NULL sigmask.

       Three independent sets of file descriptors are watched.   Those  listed in  readfds  will  be watched to see if characters become available for reading (more precisely, to see if a read will not block;  in  particular, a file descriptor is also ready on end-of-file), those in writefds will be watched to see if space is available for write (though a  large write  may  still  block),  and  those in exceptfds will be watched for exceptions.  On exit, the sets are modified in place to indicate  which file  descriptors  actually  changed  status.   Each  of the three file descriptor sets may be specified as NULL if no file descriptors are  to be watched for the corresponding class of events.

       Four  macros  are  provided to manipulate the sets.  FD_ZERO() clears a set.  FD_SET() and FD_CLR() respectively add and remove  a  given  file descriptor from a set.  FD_ISSET() tests to see if a file descriptor is part of the set; this is useful after select() returns.

       nfds is the highest-numbered file descriptor in any of the three  sets, plus 1.

The  timeout argument specifies the interval that select() should block waiting for a file descriptor to become ready.   The  call  will  block until either:

       *  a file descriptor becomes ready;

       *  the call is interrupted by a signal handler; or

       *  the timeout expires.

       Note  that  the timeout interval will be rounded up to the system clock granularity, and kernel scheduling delays mean that the blocking interval  may  overrun  by  a  small  amount.  If both fields of the timeval structure are zero, then select() returns immediately.  (This is useful for  polling.)   If  timeout  is  NULL (no timeout), select() can block indefinitely.

       sigmask is a pointer to a signal mask (see sigprocmask(2));  if  it  is not  NULL, then pselect() first replaces the current signal mask by the one pointed to by sigmask, then does the "select"  function,  and  then restores the original signal mask.

       Other than the difference in the precision of the timeout argument, the following pselect() call:

           ready = pselect(nfds, &readfds, &writefds, &exceptfds, timeout, &sigmask);

       is equivalent to atomically executing the following calls:

           sigset_t origmask;

           pthread_sigmask(SIG_SETMASK, &sigmask, &origmask);
           ready = select(nfds, &readfds, &writefds, &exceptfds, timeout);
           pthread_sigmask(SIG_SETMASK, &origmask, NULL);
           
                  The reason that pselect() is needed is that if one wants  to  wait  for either  a  signal  or  for  a  file descriptor to become ready, then an atomic test is needed to prevent race conditions.  (Suppose the  signal handler  sets  a  global  flag and returns.  Then a test of this global flag followed by a call of select() could hang indefinitely if the signal arrived just after the test but just before the call.  By contrast, pselect() allows one to first block signals, handle  the  signals  that have  come  in,  then call pselect() with the desired sigmask, avoiding the race.)

   The timeout
       The time structures involved are defined in <sys/time.h> and look like

           struct timeval {
               long    tv_sec;         /* seconds */
               long    tv_usec;        /* microseconds */
           };

       and

           struct timespec {
               long    tv_sec;         /* seconds */
               long    tv_nsec;        /* nanoseconds */
           };

       (However, see below on the POSIX.1 versions.)

       Some code calls select() with all three sets empty, nfds  zero,  and  a non-NULL  timeout as a fairly portable way to sleep with subsecond precision.

       On Linux, select() modifies timeout to reflect the amount of  time  not slept;  most  other  implementations  do not do this.  (POSIX.1 permits either behavior.)  This causes problems  both  when  Linux  code  which reads  timeout  is  ported to other operating systems, and when code is ported to Linux that reuses a struct timeval for multiple select()s  in a  loop  without  reinitializing  it.  Consider timeout to be undefined after select() returns.


RETURN VALUE
       On success, select() and pselect() return the number of  file  descriptors  contained  in  the  three  returned descriptor sets (that is, the total number of bits that are  set  in  readfds,  writefds,  exceptfds) which  may  be  zero if the timeout expires before anything interesting happens.  On error, -1 is returned, and errno is set  to  indicate  the error;  the  file  descriptor  sets are unmodified, and timeout becomes undefined.
NOTES
       An fd_set is a fixed size buffer.  Executing FD_CLR() or FD_SET()  with a value of fd that is negative or is equal to or larger than FD_SETSIZE will result in undefined behavior.  Moreover, POSIX requires fd to be a valid file descriptor.

       Concerning  the types involved, the classical situation is that the two fields of a timeval structure are typed as long (as shown  above),  and the structure is defined in <sys/time.h>.  The POSIX.1 situation is

           struct timeval {
               time_t         tv_sec;     /* seconds */
               suseconds_t    tv_usec;    /* microseconds */
           };

       where  the  structure  is  defined in <sys/select.h> and the data types
       time_t and suseconds_t are defined in <sys/types.h>.

       Concerning prototypes, the  classical  situation  is  that  one  should
       include  <time.h>  for  select().   The  POSIX.1  situation is that one
       should include <sys/select.h> for select() and pselect().

       Under glibc 2.0, <sys/select.h> gives  the  wrong  prototype  for  pse‚Äê
       lect().   Under glibc 2.1 to 2.2.1, it gives pselect() when _GNU_SOURCE
       is defined.  Since glibc 2.2.2, the requirements are as  shown  in  the
       SYNOPSIS.

BUGS
       Glibc 2.0 provided a version of pselect() that did not take  a  sigmask argument.

       Starting  with  version  2.1,  glibc provided an emulation of pselect() that was implemented using sigprocmask(2) and select().  This implementation  remained  vulnerable  to the very race condition that pselect() was designed to prevent.  Modern versions of glibc use the  (race-free) pselect() system call on kernels where it is provided.

       On  systems  that  lack  pselect(), reliable (and more portable) signal trapping can be achieved using the self-pipe trick.  In this technique, a  signal  handler writes a byte to a pipe whose other end is monitored by select() in the main program.   (To  avoid  possibly  blocking  when writing  to  a pipe that may be full or reading from a pipe that may be empty, nonblocking I/O is used when reading from  and  writing  to  the pipe.)

       Under Linux, select() may report a socket file descriptor as "ready for reading", while nevertheless a subsequent read blocks.  This could  for example  happen  when  data  has arrived but upon examination has wrong checksum and is discarded.  There may be other circumstances in which a file  descriptor is spuriously reported as ready.  Thus it may be safer to use O_NONBLOCK on sockets that should not block.

       On Linux, select() also modifies timeout if the call is interrupted  by a signal handler (i.e., the EINTR error return).  This is not permitted by POSIX.1.  The Linux pselect() system call has the same behavior, but the glibc wrapper hides this behavior by internally copying the timeout to a local variable and passing that variable to the system call.

EXAMPLE

